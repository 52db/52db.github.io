---
layout: fragment
title: 人工智能（一）机器学习和神经网络
categories: study
description: 李永乐-人工智能学习和神经网络
keywords: AI, 人工智能，机器学习，神经网络
---

## 一、人工智能发展史

### 1、1950年：

艾伦-图灵：机器能够像人类一样思考吗？并且提出了一种学习方法“图灵测试”。机器能让30%以上人相信它是一个“人”，2014年终于有一台机器，让33%的人相信它是一个13岁的小男孩，它就是首个通过图灵测试的程序“尤金-古斯特曼”。计算机领域的最高奖项就是“图灵奖”，被称为计算机领域的诺贝尔奖。

### 2、1956年：

马文-明斯基、约翰-麦卡锡以及克劳德-香农召集了一个重要会议“达特茅斯会议”。主要议题就是机器是否能够像人类一样思考，就在这个会议上人们发明了一个名词“人工智能，Artificial Intelligence”，简称“AI”。从这次会议开始，人工智能进入了第一个大发展的时代。麦卡锡也凭借他在人工智能领域发的贡献，而获得了“图灵奖”。

人工智能的三涨两落：

1、第一次浪潮：AI算法
2、第二次浪潮：知识工程系统
3、第三次浪潮：深度学习
4、第一次低谷：专家系统等的算法由于当时存在知识获取难度问题，导致很多项目失败
5、第二次低谷：计算机能力难以模拟复杂度高及规模大的神经网络。LISP机市场崩溃。经费危机，美国取消AI预算，日本第五代计算机项目失败并退出市场。

### 3、1997年 IBM 深蓝机器人

它战胜了国际象棋冠军卡斯帕罗夫，因此人工智能再次复苏。主要是还是得益于近些年计算机科学和算法的改进。尤其是计算机算法领域涌现出很多灵魂人物。

多伦多大学的杰弗里-欣顿，他的贡献在于将方向传播算法（BP）应用在人工智能方面。

纽约大学的杨易坤，他的贡献在于卷神经网络网络（CNN）。

加拿大蒙特利尔大学的约书亚-本吉奥。

他们仨获得了2018年的“图灵奖”。

经过几十年的发展，人工智能已经具有了长足进步，在特定领域，比如图像识别领域，人工智能已经超越了人类。而在计算机翻译和语音识别方面，热弄智能也有了长足的发展。

## 二、梯度下降算法

梯度下降是机器学习和优化领域中的一种常用方法，用于寻找函数的局部最小值或最大值。它是许多机器学习算法的基础，如线性回归、逻辑回归、神经网络等。梯度下降的核心思想是通过迭代地更新模型的参数，以便逐步朝着函数的极值点移动。

具体来说，梯度下降的过程如下：

### 1、初始化参数： 

首先，为模型的参数（权重和偏置）选择初始值。

### 2、计算梯度： 

在当前参数值下，计算损失函数对于每个参数的偏导数（梯度），这告诉我们如何调整参数以减少损失函数的值。

### 3、更新参数： 

使用梯度信息和一个称为学习率的超参数来更新参数。学习率控制了每次迭代中参数更新的步长。较小的学习率可能导致收敛较慢，而较大的学习率可能导致不稳定的收敛。

### 4、迭代： 

重复步骤2和步骤3，直到达到预定的停止条件，如迭代次数达到指定值或损失函数收敛到某个阈值。

梯度下降有不同的变种，主要区别在于如何计算梯度。常见的有批量梯度下降（使用所有训练数据计算梯度）、随机梯度下降（使用单个随机样本计算梯度）以及小批量梯度下降（使用一小部分样本计算梯度）。

需要注意的是，梯度下降可能会陷入局部最优解，而不是全局最优解。为了应对这个问题，有时会使用随机初始化、学习率调整策略、以及更复杂的优化算法，如Adam、RMSProp等。
