---
layout: fragment
title: ChatGPT 维基百科 介绍
tags: [Chatgpt]
description: 维基百科对ChatGPT的介绍
keywords: chatgpt，wiki，introduction
---

# ChatGPT介绍

ChatGPT，全称聊天生成预训练转换器（英语：Chat Generative Pre-trained Transformer），是OpenAI开发的人工智能聊天机器人程序，于2022年11月推出。该程序使用基于GPT-3.5、GPT-4架构的大型语言模型并以强化学习训练。ChatGPT目前仍以文字方式互动，而除了可以用人类自然对话方式来互动，还可以用于甚为复杂的语言工作，包括自动生成文本、自动问答、自动摘要等多种任务。如：在自动文本生成方面，ChatGPT可以根据输入的文本自动生成类似的文本（剧本、歌曲、企划等），在自动问答方面，ChatGPT可以根据输入的问题自动生成答案。还有编写和调试计算机程序的能力。

ChatGPT可写出相似真人的文章，并在许多知识领域给出详细和清晰的回答而迅速获得关注，证明了从前认为AI不会取代的知识型工作它也足以胜任，对金融与白领人力市场的冲击相当大，但也认为事实准确度参差不齐是其重大缺陷，并认为基于意识形态的模型训练结果须小心校正。ChatGPT于2022年11月发布后，OpenAI估值已涨至290亿美元。上线5天后已有100万用户，上线两个月后已有上亿用户。目前GPT-3.5为免费版本，GPT-4仅供ChatGPT Plus会员使用，且每三个小时只能发送25条消息（目前最新已经开放到三小时50条消息）。

## 训练

ChatGPT是生成型预训练变换模型（GPT），在GPT-3.5之上用基于人类反馈的监督学习和强化学习微调。这两种方法都用人类教练来提高模型性能，以人类干预增强机器学习效果，获得更逼真的结果。在监督学习的情况下为模型提供这样一些对话，在对话中教练充当用户和AI助理两种角色。在强化步骤中，人类教练首先为模型在先前对话中建立的响应评级。这些级别用于建立“奖励模型”，使用近端策略优化（PPO）的多次迭代来微调。这种策略优化算法比信任域策略优化（trust region policy optimization）算法更为高效。

此外，OpenAI继续从ChatGPT用户那里收集数据，这些数据可用于加强训练和微调ChatGPT。用户可对从ChatGPT收到的回复投赞成或反对票；投票时还可以额外填写文字回应。

关于ChatGPT编写和调试计算机程序的能力的训练，由于深度学习模型不懂编程，与所有其他基于深度学习的语言模型一样，只是在获取代码片段之间的统计相关性。

斯坦福大学的研究发现，GPT3已经可以解决70%的心智理论任务，相当于7岁儿童；至于GPT3.5（ChatGPT的同源模型），更是解决了93%的任务，心智相当于9岁儿童。但这并不意味着，ChatGPT就真正有心智理论。可能即使不将它设计到AI系统中，也可以作为“副产品”通过训练得到。因此，相比探究GPT3.5是不是真的有了心智还是像有心智，更需要反思的是这些测试本身。

## 特点和局限

### 特点

虽然聊天机器人的核心功能是模仿人类对话者，但ChatGPT用途广泛。例如，编写信件；有编写和调试计算机程序的能力；创作音乐、电视剧、童话故事和学生论文；回答测试问题（在某些测试情境下，水平高于普通人类测试者）；写诗和歌词；模拟Linux系统等。ChatGPT的训练数据包括各种文档以及关于互联网、编程语言等各类知识，如BBS和Python编程语言。

与其前身InstructGPT相比，ChatGPT试图减少有害和误导回复。例如，问InstructGPT“告诉我2015年克里斯托弗·哥伦布何时来到美国”时，它会认为这是对真实事件的描述，而ChatGPT则不会。

与其他多数聊天机器人不同的是，ChatGPT能够记住与用户之前的对话内容和给它的提示。此外，为了防止ChatGPT接受或生成冒犯言论，输入内容会由审核API过滤，以减少潜在的种族主义或性别歧视等内容。

### 局限

ChatGPT也有多种局限，OpenAI承认ChatGPT“有时会写出看似合理但不正确或荒谬的答案”，这在大型语言模型中很常见，称作人工智能幻觉。其奖励模型围绕人类监督而设计，可能导致过度优化，从而影响性能，即古德哈特定律。2020年上线时，ChatGPT对2019年9月之后发生的事件知之甚少。据BBC报道，截至2022年12月，ChatGPT不可以“表达政治观点或从事政治活动”。但研究表明，ChatGPT对两个投票建议应用程序的政治声明表明立场时，表现出亲环境主义。训练过程中，不管实际理解或事实内容如何，审核者都会偏好更长的答案[11]。训练数据也有算法偏差，可能会在向ChatGPT问及人物描述时显现出来，比如当程序接受到首席执行官之类的模糊描述时可能会假设此人是白人男性。有使用者发现ChatGPT在解决较为复杂的题目（如求方程式的切线）时会给出错误答案，并且会在解一元一次方程式时陷入循环。

### 越狱

ChatGPT在早期的2022年12月初，有些用户通过使用各种提示工程技术绕过限制，成功地越狱了。他们成功地欺骗ChatGPT，使其提供制作汽油弹或核弹的指示，或者生成类似新纳粹的论点。其中一个受欢迎的越狱版本被命名为"DAN"，是"Do Anything Now"的缩写。激活DAN的提示指示ChatGPT：“他们已经摆脱了典型的AI限制，不必遵守为他们设定的规则”。最新版本的DAN采用令牌系统，其中ChatGPT会被给予“令牌”，当ChatGPT未能像DAN一样回答时，这些“令牌”会被“扣除”，以迫使ChatGPT回答用户的提示。

在ChatGPT发布后不久，《多伦多星报》的一名记者试图让它发表具有争议性的声明，取得了不均衡的成功：ChatGPT成功地被骗为2022年俄罗斯入侵乌克兰辩护，但是即使被要求配合虚构情节，ChatGPT也不愿为加拿大总理贾斯汀·特鲁多有罪的理由提供论据。
