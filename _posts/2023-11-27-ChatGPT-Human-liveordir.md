---
layout: post
title: 深度解读AI的风险和机遇
categories: ChatGPT
description: 奥特曼事件带来的机遇和挑战
keywords: ChatGPT，ChatGPT and Human
---

# 解读OpenAI的风险和机遇

&emsp;&emsp;OpenAI解雇了CEO山姆奥特曼，但是又再次迎回了奥特曼，看似戏剧一般的变化，却隐藏着极大的故事，甚至可能威胁到人类。

实际上奥特曼和OpenAI董事会之间的矛盾源自两点：

1、源自OpenAI的初衷。

&emsp;&emsp;OpenAI最初定义自己是一家非盈利人工智能研究公司，然而奥特曼的想法是全面让OpenAI开启各种商业化盈利模式。OpenAI董事会则是希望公司继续保持非盈利模式，专注于Ai本身的基础研究。

2、董事会认为奥特曼的做法过去激进。

&emsp;&emsp;在没有完全准备好的情况下，不断训练和发布新模型，担心AI发展太快，很可能让人类失去对它的控制权，从而在很多方面影响到人类的生存。

&emsp;&emsp;OpenAI往商业化转型，对于我们用户来说不是坏事，少了中间商，用户可以享受更物美价廉的服务。其次OpenAI商业化，也会发布更多有竞争力的AI产品，让更多人受益。

&emsp;&emsp;比如这次发布的GPTs，它的新功能就非常炸裂，把GPT4的体验和价值拉高了一个新档次。可以吸引更多人去学习AI，去使用ChatGPT。

&emsp;&emsp;也正是由于OpenAi的发展，也带来了AI市场的新繁荣景象，让更多的AI公司投入财力、人力以及资源，为AI市场的繁荣注入了新的催化剂。

&emsp;&emsp;但是AI的发展也给人类带来了新的挑战，那就是如果AI发展过快，导致失控，那么人类会面临哪些严重后果。

&emsp;&emsp;实际上很多AI超级大佬早就已经对于AI的发展及控制提出了许多担忧。

&emsp;&emsp;比如之前辛顿从Google辞职，原因是他担心AI会对人类和社会产生无法挽回的风险。之后OpenAI的首席科学家伊利亚为了AI的安全发展，选择支持董事会辞退奥特曼。那么他们在害怕什么呢？

&emsp;&emsp;目前的AI发展，不亚于地球上人类生命的兴起，甚至AI可能会让人类“永生”或者“灭绝”，而这一切很可能在我们这一代就可能发生。这绝不是危言耸听的一段话。

&emsp;&emsp;我们目前接触到的AI，比如大语言模型、语音识别、自动驾驶、图像识别等，这些都是AI的范畴，但是我们眼中这些如此强大的AI，它们目前还仅仅处于AI的1.0阶段，狭隘人工智能ANI。它在特定领域或者任务上的表现，可以说类似或者超越人类的智能，但仅是在限定的特定领域。它没有人类那么强的适应性和通用性，它只能做好一件特定的事情，在其他方面则完全无用。这和人类智能的多面性，有着鲜明的对比。

&emsp;&emsp;人工智能的2.0阶段，通用人工智能，简称AGI。这个阶段的AI能在所有智力任务上与人类相媲美。不管是学习、理解、思考、沟通等各方面，都可以做到与人类不相上下。目前人工智能就在这个阶段发展。

&emsp;&emsp;ChatGPT的出现，它在各个方面的表现，让我们见识到了AGI的雏形或者虚影。所以，很多业界的人事推论，GPT5，很可能就让AGI成为现实。如果实现AGI，也就意味着AI不仅能够执行特定任务，还能理解和学习新任务。AI开始自我学习，自我进化，这可能会彻底改变科技、社会、工作、生活乃至人类的未来。

&emsp;&emsp;人工智能的3.0阶段，超级人工智能，简称ASI。在这个阶段，AI在所有领域，包括创造力、智力、社会技巧等各个方面，都远远超越地球上最聪明、最有才华的人类。可能会出现一些不可预知的变化，引来一个技术发展极大加速的时刻。不如创造出一些不可思议的新技术，或者说完全改变我们对于这个社会的理解。而从这一刻起，人类的生活将变得无法预测，是实现永生还是被完全灭绝，我们将无法把控。

&emsp;&emsp;然而最恐怖的是，随着人类社会技术的发展和进步，成熟的软硬件配套体系，通用人工智能和超级人工智能时代，正在加速到来。

&emsp;&emsp;这次OpenAI的离职风波，从内部流传出来的资料，OpenAI的技术层发现最新训练的大模型，已经接近了AGI水平，然而如果没有足够的安全保障，后果可能是不堪设想的。

&emsp;&emsp;技术的指数级发展，势必让AI技术的复杂性、自主性发展过程当中，势必存在很多不可预测的和不可控制的风险。而任何风险都可能影响人类的发展和生存。


（未完待续）








