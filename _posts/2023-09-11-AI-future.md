---
layout: post
title: 人工智能未来发展的底层逻辑
categories: AI
description: 越来越卷的人工只能未来会如何发展
keywords: AI, machine learning, deep learning
---

# 人工智能未来发展的底层逻辑

## 未来人工智能的发展方向

### AI智能遇到了天花板？

&emsp;&emsp;谷歌的Jeff Dean做了一个AI智能的提升工作，然而当他完成了这些工作，就他的数据结果发现，他所做的工作仅仅比以前所做的工作提高了0.03%，但是却花费了5万7千美元。如果是普通高校或者普通公司，甚至都不可能去复现这样的哦你工作。

&emsp;&emsp;对这个事情，有如下看法：

&emsp;&emsp;首先第一，确实以深度神经网络技术为主导的人工智能，目前确实大厂逐渐走向了所谓的暴力美学，就是用超大规模的数据加超大规模的算力，去探索深度神经网络，它的天花板到底在哪？

&emsp;&emsp;第二就是从学术科研来说，也许这并不是唯一的一条路。目前有大量的一些研究是去探索一些其他的技术路线，怎样做到从感知智能往认知智能去做的这样一个转变。还有一些小样本的任务，怎样利用一些非常小的，这样一些数据量去做一些相关的人工智能事情。

&emsp;&emsp;第三就是从工业界来看，所有的事情未必需要这么大的算力，其实工业界也有大量的非语音图像或者文本这样的任务用，这也逼着学术界推出一些比较高效的一些算法。

### AI算法并不只有深度神经网络？

&emsp;&emsp;在90年代之前，人工智能的概念它所代表的背后的技术，可能主要还是以符号主义，就是基于这些逻辑推理、Planning、Searching这样的技术，这个世纪的从10年往后可能更重要的一次转变就是用神经网络的技术来更好的去表示这些感知类的任务。

&emsp;&emsp;但是目前其实还有大量的人工智能的所谓的。比如说"圣杯"问题并没有解决，比如说像怎么样的去做逻辑推理，怎么样的去做常识，怎么样更好的去对记忆来去做建模。这些事情是不是神经网络就足够。这可能是目前学术界、甚至工业界，下一步大家更关心的事情。


### 现在的人工智能的研究可能更多的集中在感知领域，但是在认知领域可能并没有突破性的进展，这会是新的人工智能的未来的发展方向吗？

&emsp;&emsp;我们所说的感知人工智能，其实就是最近几年来，人工智能成功落地的，比如说图像识别、说语音转文字这样的应用、或者比如说一些文本的生成，这样的一些任务。

&emsp;&emsp;更重要的可能是怎么样的从这种感知类的任务转向一些具有一些认知能力的事情。尤其是怎样的用人工智能的方式去实现逻辑推理去实现常识等等。

目前大概根所知，学术界大概主要还是有三条技术路线

&emsp;&emsp;第一条，就是继续沿着神经网络这条路走下去，就是说通过不断的堆数据，然后去堆算力来去看一看，这是否有可能；

&emsp;&emsp;第二条，尝试去同之前的这些符号主义的这些技术来去做结合，所谓的神经主义加符号主义的结合；

&emsp;&emsp;第三条，将传统的逻辑推理的技术再做一些新的提升。

### 数据【数字石油】的重要性

&emsp;&emsp;数据对于人工智能工程来说重要性已经越来越高了，甚至现在工业界提出了一个概念叫做以“数据为中心的开发模式”，之前叫做“以模型为中心”。

&emsp;&emsp;意思就是，之前大概工程师更多的时间，在于怎么样搭建一个模型，怎么样去调参，让这个系统的性能更好。现在呢，可能80%左右的注意力都在，怎么样的让我的数据集变得更好，怎么样让我的训练集变得更好，怎么样让我的训练集更平衡，让我的模型在好的数据集上训练之后能够得到一个比较好的这样的结果。

&emsp;&emsp;随着包括对数据隐私需求逐渐的增长，包括数据所带来的一些副作用，或者说数据所带来的一些非技术的要求越来越多了。比如说当几家机构如果要做联合建模的时候，数据不能够在机构之间分享。包括像联邦学习这样的技术，就是为了在满足数据隐私保护的情况下来做联合建模，现在大家已经逐渐的意识到在具体的工业开发中，可能每家机构不一样的地方，就是他们现在的数据，有了非常便利的软件的开源的框架，有了非常高效的硬件的这些实现。可能目前工程师大量的时间，都转而去关注他自己的数据了。这是一个范式级别的转变。

### 对人工智能的发展来说，还有哪些遇到的问题？

&emsp;&emsp;处理数据的能力，和存储数据的能力，包括存储数据的带宽，中间可能存在着一定的鸿沟，也被称之为的“数据墙”。这样的问题是关于数据，现在存在的一个比较大的问题。

&emsp;&emsp;一家以AI技术为核心的这样的一个公司，就遭遇到了比较重要的一个问题，就是怎么样打破内存墙。像这样的公司内部每天需要存储的数据量都是海量的，大概是25~30TB/天。在这样大量的这种任务下，所做的很重要的一件事情，就是把数据分成“冷数据”、“温数据”跟“热数据”。

* “冷数据”大概指的是公司内部访问的频率不是很高，落库就好。适合存储在硬盘。

* “热数据”大概指的是公司做大量的一些读写任务，而数据一般来说都比较的散，每一次读写的量又非常的大，性能要求又很高，适合存储在内存。

* “温数据”大概指的是访问频率比较高，数据量较大，适合放在SSD中。

&emsp;&emsp;这样的分布式的存储有利于减缓“内存墙”的问题。

### 芯片和硬件是为AI量身定制？

&emsp;&emsp;人工智能应用有“三驾马车”，就是算力、数据、还有算法。上面说了算法和数据，现在来看看算力。

&emsp;&emsp;现在有个很火的概念叫“云原生”。“云原生”促进了整个云基础设施的一个重构，从这个角度看，人工智能是否会推动IT基础设施架构的一个新的重构。也就是说所谓的这种AI原生的基础设施架构会出现吗？

&emsp;&emsp;实际上这样的情况已经在真实的发生了，尤其是从过去的十年对于云端的可信计算这样的需求越来越多。比如说模型的计算过程，是一个公司的核心的知识产权，如果把它放到云端的话，或者放到一个共有的平台上的话，就有可能会担心计算过程会有被窃取的风险。在这种情况下有没有一些硬件的解决方案，可能这个就是一个非常典型的从需求出发，然后让芯片厂商、或者硬件厂商来提供相应的解决方案。现在一些人工智能公司用的一些技术，比如说在英特尔芯片上的SGX上做的一些测试，就是用这样的一个隐私沙盒，能够保障公司的所有的计算，以硬件的方式来得到一定程度的保护，这其实是跨机构之间合作的一个非常重要的基础。

### 人工智能就等同于GPU，或者是说人工智能的算力就等同于使用GPU去做训练，这样的说法对吗？

&emsp;&emsp;这样的说话确实稍微片面一些。

&emsp;&emsp;比如说以现在的人工智能公司，每天日常做的工作，就是在做量化交易的时候，如果把数据从CPU拷贝到GPU上，再拷贝回来，对于很多的量化交易的任务已经来不及了。也就是说其实人工智能公司，需要有一个非常高性能实现的CPU版本的人工智能模型的实现。

&emsp;&emsp;再比如说有很多的一些任务，需要在网卡上，直接的对一些数据来做分析跟处理，网卡上一般会带的一个FPGA的这样的芯片，这个东西其实它也是，如果要传到GPU上，就更来不及了。

&emsp;&emsp;对于这种低延时，又需要人工智能技术的帮助的这些场景，可能需要异构的这样的一个架构。也就是说不管是PGA、ASIC还是CPU、还是GPU，它们是在不同的场景下，有它不同的用武之地。

### 异构系统如何编程和控制？

&emsp;&emsp;现在整个的芯片行业的发展，是从一个通用转向异构的这样一个大的环境，但是这其实也有很多这样的问题，比如说这么多种不同的类型的芯片，如何把它们做成一个完整的系统，如何去对它进行统一的编程，或者是统一的调度和控制。

&emsp;&emsp;目前在工业界有一些这样尝试，比如说像英特尔正在做的oneAPI，这是一个非常重要的工具，就是说用这个解决方案，同样一套代码，可以把它理解成为一种特殊的编译器，它能够自动的转换成为分别在CPU上跑，或者在FPGA，或者在其它类型芯片上跑的程序。这将会大大的减少工程师这边的困难，或者说能够的让工程师更专注在做算法上。这是一个推动异构应用的一个非常重大的事情。

### 从系统的角度软硬件的角度，未来人工智能的发展的方向都还有哪些创新？

&emsp;&emsp;现在的人工智能领域需要一个更好的端到端的解决方案，可以这样说，现在已经从所谓的软件1.0升级到了软件2.0时代。

&emsp;&emsp;就是说从传统的规则驱动的复杂的软件工程的构建，变成了数据驱动这样的一个软件工程的构建方法。在之前，要用非常好的聪明才智，去写一系列精妙的系统，让整个的程序能够跑起来，现在我们正走向软件工程时代，这一套规则，不知道该怎么定。可以直接把它甩给大量的数据，或者说甩给一套机器学习算法，然后这个算法会生成一个新的算法，而这个新的算法是人工智能领域想得到的东西。

&emsp;&emsp;这有点类似于像去造一些造机器人的机器人，可以称之为数据驱动。

&emsp;&emsp;在软件2.0时代，整个的软件工程的开发范式，将会得到一个比较大的一个转变，很希望得到的一种端到端的这样一套解决方案。核心就是怎样更方便的来去做这种以数据为中心的软件工程的开发。

### 人工智能的未来关键是如何落地？

&emsp;&emsp;很多人都在说现在人工智能的技术发展，其实最大的问题就是它的落地的问题，有这么多的技术，有这么多的先进的算法，有这么多的数据和方法，最后怎么让人工智能有一个很好的落地？

&emsp;&emsp;第一，从工业界来看。还是要从第一性原理出发，就是说还是要从自己的需求出发，然后要综合考虑到很多的一些非技术的因素，从需求跟成本出发，找到一些解决方案。

&emsp;&emsp;第二，从学术来说的话，未必要做跟风，非要做大量的数据。其实有大量的一些任务，就是需要小规模的参数，比如限于成本，也有一些地方只有小量的样本，限于现实的限制情况，怎样去做一些创新跟突破，这可能是学术界应该去主动担起的一个责任。

### 今后是否会有一个统一的基础设施，让所有人工智能领域的人去使用这样一种专业平台？

&emsp;&emsp;在人工智能领域，有的人可能更多专攻在算法领域，有些可能更多的专攻在数据领域，可能更多的是应用在算力领域，而如果让每个人做一些不适合自己的事情，反而会引起事倍功半的结果。但是如果能有一个统一的平台，同时兼顾性能，比如说用异构的这种方式，去兼顾不同应用的性能，然后通过一个统一的编程的接口，让大家都能够去应用到这个平台本身，能够充分的发挥每一个人的优势。而不是各自发展，造成大量的人力、数据、算力，算法的浪费。

&emsp;&emsp;这可能是未来的一个发展方向，人工智能技术在2015年左右的时候，搭一套深度学习，然后还要在GPU上能跑起来，全球可能不会超过1000个人。现在，已经达到了指数级别的增长，很多人都会做这样的事情。有理由相信大概在5年之后任何一个程序员的工具包里。就有一个更为丰富的人工智能解决方案。人工智能实现的门槛，在不断的降低，只有这样，人工智能的技术才能更为普遍的应用在每一个技术公司，甚至是非技术公司。

&emsp;&emsp;所以像所谓的大厂里头的人工智能实验室必然会消失。当大厂里人工智能实验室消失的时候，大概就是人工智能真正遍地开花的年代。

### 人工智能未来的发展，路在何方？

&emsp;&emsp;第一，人工智能未来发展可能还需要摩尔定律的加持，它的算力的要求还是比较大的，可能通过硬件的进一步迭代，或者是算法的进一步更新，能够让目前需要在集群上跑的事情，最后可能转移到手机上就可以，这样才有可能有大量的落地可能。

&emsp;&emsp;第二，就是互联网，从传统的这些感知类的任务，转向一些传统行业。之前人工智能领域投入的精力都在想，怎样用人工智能技术去做一个更好的视觉的解决方案，或者一个更好的推荐系统，或者更好的一个具备人工只能技术的软件系统。但是在实体经济中，其实有大量产生数据的部门或者业务，在当这些数据能够更好的信息化之后，这些数据所带来的价值，可能远超目前的虚拟经济。

所以说从算力上来说，可能人工智能领域还需要再经过几年的摩尔定律的加持，然后从应用场景来说转向实体经济，那么人工智能可能迎来更广大的应用天地和领域。




-----------------------










